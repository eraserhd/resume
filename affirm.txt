The vision for the Batch Infra team @ Affirm team is to provide reliable, scalable, self-serve and Affirm-optimized compute solution to enable ML, Product, and Financial Engineering success. Our team is responsible for building and maintaining compute platform that serves as a backbone for processing various Business critical batch workloads at Affirm through a wide suite of scheduled and on-demand compute solutions built on the cloud. Affirm is growing rapidly and so is the need for reliable and high availability frameworks. If solving infrastructure challenges at scale excites you, come join us!

What You’ll Do

    Shape the technical direction, strategy, and roadmap for Batch Infra platform that forms the backbone for several thousands of offline workloads at affirm.
    Design and build data infrastructure systems, services and tools to handle new Affirm products and business requirements that securely scale over millions of users and their transactions.
    Build frameworks and services which will be used by other engineering teams at Affirm to manage billions of dollars in loans and power customer experiences.
    Improve the reliability and efficiency of the Batch Infrastructure at scale and high reliability.
    Engage other teams at Affirm about their use of the Batch platform to ensure we are always building the right thing.
    Take an active role in mentoring junior engineers, lead and implement the processes that support team growth and efficiency.

What We Look For

    Strong sense of ownership with a proven track record of successfully driving large cross-functional technical programs.
    Experience building and owning large-scale, geographically distributed compute, and data processing systems.
    Experience building and owning data lake solutions like Iceberg, Hudi, Delta, etc.
    Experience building and managing Workflow Orchestration frameworks like Airflow, Flyte, Prefect, Temporal, Luigi, etc.
    Experience with or working knowledge for efficiently scaling frameworks like Spark/Flink for extremely large scale datasets on Kubernetes.
    Skilled at developing and debugging in Python/Kotlin or the ability to learn them quickly.
    Working knowledge of Relational and NoSQL databases.
    Experience with AWS and/or other cloud providers.
    Technical leadership; capable of handling mentorship, cross functional project execution, and solid individual contribution.
    Demonstrated ability to deliver on complex technical projects by collaborating closely with stakeholders.
    Eager to learn new things and have a growth mindset.
    Well-developed interpersonal, written and verbal communication.
    Experience working in the data infrastructure domain.
    This position requires either equivalent practical experience or a Bachelor’s degree in a related field

